{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "from edward.models import Normal, Empirical, Gamma\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.distributions import bijectors\n",
    "import numpy as np\n",
    "\n",
    "N = 20\n",
    "N_test = 100\n",
    "epochs = 40\n",
    "layers = [100]  # CONST\n",
    "activation_fn = \"relu\"\n",
    "\n",
    "# Chosen by https://www.random.org/coins/?num=31&cur=60-usd.0025c-ct\n",
    "r = np.random.RandomState(0b0001101100010011010011110101110)\n",
    "true_sigma = 3.0\n",
    "X_train = r.uniform(-4, 4, N)\n",
    "y_train = X_train ** 3 + r.normal(scale=true_sigma, size=N)\n",
    "X_train = X_train.reshape([-1, 1])\n",
    "size_train = N\n",
    "X_test = np.linspace(-6, 5, N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BNN in Edward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from edward.models import Normal, Empirical, Gamma\n",
    "\n",
    "# Multiple options for handling (x, y)...\n",
    "x = tf.placeholder(tf.float32, [None])\n",
    "y = tf.placeholder(tf.float32, [None])\n",
    "gamma = Gamma(6.0, 6.0)\n",
    "lambd = Gamma(6.0, 6.0)\n",
    "\n",
    "b1 = Normal(tf.zeros([100]), tf.ones([100]) / tf.sqrt(lambd))\n",
    "w1 = Normal(tf.zeros([100]), tf.ones([100]) / tf.sqrt(lambd))\n",
    "a1 = tf.matmul(tf.reshape(x, (-1, 1)), tf.reshape(w1, (1, -1))) + b1\n",
    "z1 = tf.nn.relu(a1) # [N, 100]\n",
    "b2 = Normal(tf.zeros([1]), tf.ones([1]) / tf.sqrt(lambd))\n",
    "w2 = Normal(tf.zeros([100]), tf.ones([100]) / tf.sqrt(lambd))\n",
    "out = tf.reshape(tf.matmul(z1, tf.reshape(w2, (100, 1))) + b2, [-1])\n",
    "y_pred = Normal(out, 1.0 / tf.sqrt(gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HMC in Edward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ITERS = 30000\n",
    "qb1 = Empirical(tf.Variable(tf.zeros([ITERS, 100])))\n",
    "qw1 = Empirical(tf.Variable(tf.zeros([ITERS, 100])))\n",
    "qb2 = Empirical(tf.Variable(tf.zeros([ITERS, 1])))\n",
    "qw2 = Empirical(tf.Variable(tf.zeros([ITERS, 100])))\n",
    "qgamma = Empirical(tf.Variable(tf.zeros([ITERS])))\n",
    "qlambda = Empirical(tf.Variable(tf.zeros([ITERS])))\n",
    "\n",
    "# Question, how to get HMC to look at all the data at once.....\n",
    "inference = ed.HMC({w1: qw1, w2: qw2,\n",
    "                    b1: qb1, b2: qb2,\n",
    "                    gamma: qgamma, lambd: qlambda},\n",
    "                   data={y_pred: y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [100%] ██████████████████████████████ Elapsed: 77s | Acceptance Rate: 0.260\n"
     ]
    }
   ],
   "source": [
    "# Simple version\n",
    "inference.run(step_size=0.01, n_steps=4)\n",
    "\n",
    "\n",
    "# Variable-sized mini-batches\n",
    "# -- Needed for test set??\n",
    "inference.initialize(n_iter=ITERS, step_size=0.5 / N, n_steps=2)\n",
    "tf.global_variables_initializer().run()\n",
    "for _ in xrange(ITERS):\n",
    "    info = inference.update({\n",
    "            x: X_train.reshape(-1).astype(np.float32),\n",
    "            y: y_train.reshape(-1).astype(np.float32)})\n",
    "    inference.print_progress(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction in Edward\n",
    "\n",
    "Supposedly, various methods work, but in my (LIMITED) experience, I disagree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Manually remove the burn in\n",
    "egamma = tf.nn.softplus(qgamma.params).eval()[ITERS/2:]\n",
    "elambda = tf.nn.softplus(qlambda.params).eval()[ITERS/2:]\n",
    "eb1 = qb1.params.eval()[ITERS/2:, :]\n",
    "ew1 = qw1.params.eval()[ITERS/2:, :]\n",
    "eb2 = qb2.params.eval()[ITERS/2:, :]\n",
    "ew2 = qw2.params.eval()[ITERS/2:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `ed.copy`\n",
    "\n",
    "Edward's recommended way to sample from posterior predictive (but not Evan's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_post = ed.copy(\n",
    "    y_pred,\n",
    "    feed_dict={\n",
    "        w1: ew1, w2: ew2,\n",
    "        b1: eb1, b2: eb2,\n",
    "        gamma: egamma, lambd: elambda,\n",
    "        x: X_test.reshape(-1).astype(np.float32)})\n",
    "y_post.sample(100000).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, each sample uses iid draws from each \"distribution\" (`ew1`, `ew2`, ...), rather than value from same iteration in the MCMC.\n",
    "\n",
    "Note: this is what we want with variational methods, but not necessarily MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [100%] ██████████████████████████████ Elapsed: 14s | avg y[0]: -90.855\n"
     ]
    }
   ],
   "source": [
    "# Edward has a nifty progress bar included...\n",
    "pr = ed.Progbar(target=ITERS/2)\n",
    "\n",
    "for i in xrange(ITERS/2):\n",
    "    y_post = ed.get_session().run(y_pred,\n",
    "        feed_dict={w1: ew1[i, :], w2: ew2[i, :],\n",
    "        b1: eb1[i, :], b2: eb2[i, :],\n",
    "        gamma: egamma[i], lambd: elambda[i],\n",
    "        x: X_test.reshape(-1).astype(np.float32)})\n",
    "    \n",
    "    # do something with y_post...\n",
    "    \n",
    "    pr.update(i + 1, values={'avg y[0]': y_post[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### TF Problems\n",
    "TensorFlow will make new elements of the graph if you're not careful. Edward isn't helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for i in xrange(ITERS/2):\n",
    "    y_post = ed.get_session().run(y_pred.mean(),    # Change y_pred to y_pred.mean()\n",
    "        feed_dict={w1: ew1[i, :], w2: ew2[i, :],\n",
    "        b1: eb1[i, :], b2: eb2[i, :],\n",
    "        gamma: egamma[i], lambd: elambda[i],\n",
    "        x: X_test.reshape(-1).astype(np.float32)})\n",
    "    # do something..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Would show results, but REALLY slow. Stopped after 12k iters, tried to show mean, got a segfault..... in Python........\n",
    "\n",
    "The problem is that `y_pred.mean()` **apparently** creates a new `Tensor` every time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BNN in Stan\n",
    "The following are in the Stan langauge (slightly out of order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    real x[N];\n",
    "    real y[N];\n",
    "\n",
    "    int<lower=0> N_test;\n",
    "    real x_test[N_test];\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "parameters {\n",
    "    real<lower=0> lambda;\n",
    "    real<lower=0> gamma;\n",
    "    row_vector[100] b1;\n",
    "    matrix[1, 100] w1;\n",
    "    row_vector[1] b2;\n",
    "    matrix[100, 1] w2;\n",
    "}\n",
    "\n",
    "// Easy to interpret prior and likelihood.\n",
    "model {\n",
    "    lambda ~ gamma(6.0, 6.0);\n",
    "    gamma ~ gamma(6.0, 6.0);\n",
    "    b1 ~ normal(0.0, 1 / sqrt(lambda));\n",
    "    // Distributions will \"vectorize\" but not \"matricize\"\n",
    "    to_vector(w1) ~ normal(0.0, 1 / sqrt(lambda));\n",
    "    b2 ~ normal(0.0, 1 / sqrt(lambda));\n",
    "    to_vector(w2) ~ normal(0.0, 1 / sqrt(lambda));\n",
    "\n",
    "    y ~ normal(to_vector(network(to_matrix(x, N, 1), w1, b1, w2, b2)), 1 / sqrt(gamma));\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "functions {\n",
    "  matrix network(matrix x, matrix w1, row_vector b1, matrix w2, row_vector b2) {\n",
    "    {\n",
    "      matrix[rows(x), 100] z;\n",
    "      z = x * w1 + rep_matrix(b1, rows(x));\n",
    "      // Theoretically, traversing in column-order is faster\n",
    "      for (j in 1:100) {\n",
    "        for (i in 1:rows(x)) {\n",
    "          // Will not vectorize or matricize\n",
    "          z[i, j] = fmax(z[i, j], 0.0);\n",
    "        }\n",
    "      }\n",
    "      return z * w2 + rep_matrix(b2, rows(x));\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "// data, transformed data, parameters, transformed parameters, model\n",
    "\n",
    "generated quantities {\n",
    "  matrix[N_test, 1] y_test;\n",
    "  {\n",
    "    matrix[N_test, 1] out;\n",
    "    out = network(to_matrix(x_test, N_test, 1), w1, b1, w2, b2);\n",
    "    for (i in 1:N_test) {\n",
    "      y_test[i, 1] = normal_rng(out[i, 1], 1 / sqrt(gamma));\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_371be447302174281a07fb2533155549 NOW.\n"
     ]
    }
   ],
   "source": [
    "import pystan\n",
    "\n",
    "# Compiles code -- can pass in a string instead.\n",
    "sm = pystan.StanModel(file='toy.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "d = {'x': X_train.reshape(-1),\n",
    "     'y': y_train,\n",
    "     'N': len(y_train),\n",
    "     'x_test': X_test.reshape(-1),\n",
    "     'N_test': len(X_test)}\n",
    "\n",
    "# 30000 burn-in, 30000 samples, default NUTS sampler, 2 parallel chains\n",
    "fit = sm.sampling(data=d, iter=30000, chains=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Logging is good, but if using Jupyter, logs to terminal instead (at least by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Posterior predictive samples\n",
    "y_sample = fit.extract(permuted=True, inc_warmup=False)['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
